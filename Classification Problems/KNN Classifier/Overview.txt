KNN classifier standard implementation using scikit-learn.
KNN stands for K-Nearest Neighbors, a simple and effective machine learning algorithm used for classification and regression tasks. 
KNN searches for K nearest data points in the training set to make predictions for new data points. Since it useds the entire training dataset during prediction, it is considered a lazy learning algorithm.
There are many ways to calculate the distance between data points, with Euclidean distance being the most commonly used metric


Data Set Description:
DataSet consists of features such as Age, BP, cholestrol, Na_to_K and a target variable Drug which indicates the type of drug prescribed.
The objective is to classify the type of drug based on the given features using KNN classifier.

Model Implementation:
1. The dataset consisted of categorical and numerical features. Categorical features were encoded using one-hot encoding.
2. The data set was not balanced, so SMOTE (Synthetic Minority Over-sampling Technique) was applied to balance the classes.
3. The dataset so obtainsed was split into training and testing sets using an 80-20 split.
4. A KNN classifier was instantiated with n_neighbors set to 5.

Model evaluation:
1. The predicted model is then evaluated using accuracy score, confusion matrix, and classification report.
